{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Notebook\n",
        "##### WEEK 3: Prompt Engineering"
      ],
      "metadata": {
        "id": "14WI-JV4AcWN"
      },
      "id": "14WI-JV4AcWN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "\n",
        "* Build a ‚ÄúPrompt Notebook‚Äù that contains at least 6 prompt variants per task (summarize, rewrite for tone, extract facts) with outputs and short evaluations (fluency, faithfulness, usefulness).\n",
        "\n",
        "* Create a short rubric (3‚Äì5 criteria) to score prompts and apply it to your prompt notebook.\n",
        "\n",
        "Mini Project: Prompt library notebook + scoring rubric."
      ],
      "metadata": {
        "id": "zizU2dGoBHdo"
      },
      "id": "zizU2dGoBHdo"
    },
    {
      "cell_type": "markdown",
      "id": "87857393-6369-4b66-87c9-5f3253edf28e",
      "metadata": {
        "id": "87857393-6369-4b66-87c9-5f3253edf28e"
      },
      "source": [
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.getLogger(\"tornado.access\").setLevel(logging.CRITICAL)\n"
      ],
      "metadata": {
        "id": "m3CRAmAw4P55"
      },
      "id": "m3CRAmAw4P55",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "key = getpass(\"Enter your GOOGLE_API_KEY (hidden): \")\n",
        "\n",
        "with open(\".env\", \"w\") as f:\n",
        "    f.write(f\"GOOGLE_API_KEY={key}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N7FtpSQ2qhM",
        "outputId": "1a02c044-b74f-4c0e-bd82-b0a8f2306ec2"
      },
      "id": "1N7FtpSQ2qhM",
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GOOGLE_API_KEY (hidden): ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "import google.generativeai as genai\n",
        "\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "def get_completion(prompt, model=\"gemini-2.5-flash\"):\n",
        "    model = genai.GenerativeModel(model)\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n"
      ],
      "metadata": {
        "id": "e8MPIdWA2x5y"
      },
      "id": "e8MPIdWA2x5y",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5d95eba0-7744-491a-a30a-8ee687303b7a",
      "metadata": {
        "id": "5d95eba0-7744-491a-a30a-8ee687303b7a"
      },
      "source": [
        "## Summarizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1fb6a900",
      "metadata": {
        "height": 302,
        "id": "1fb6a900"
      },
      "outputs": [],
      "source": [
        "attention = \"\"\"\n",
        "The dominant sequence transduction models are based on complex recurrent or \\\n",
        " convolutional neural networks that include an encoder and a decoder. The best \\\n",
        " performing models also connect the encoder and decoder through an attention \\\n",
        " mechanism. We propose a new simple network architecture, the Transformer, \\\n",
        " based solely on attention mechanisms, dispensing with recurrence and convolutions \\\n",
        " entirely. Experiments on two machine translation tasks show these models to \\\n",
        " be superior in quality while being more parallelizable and requiring significantly \\\n",
        " less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English \\\n",
        "to-German translation task, improving over the existing best results, including \\\n",
        " ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, \\\n",
        " our model establishes a new single-model state-of-the-art BLEU score of 41.8 after \\\n",
        " training for 3.5 days on eight GPUs, a small fraction of the training costs of the \\\n",
        " best models from the literature. We show that the Transformer generalizes well to \\\n",
        " other tasks by applying it successfully to English constituency parsing both with \\\n",
        " large and limited training data.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "51ebde54",
      "metadata": {
        "height": 183,
        "id": "51ebde54",
        "outputId": "9b7e164a-0009-4fb8-805a-2ed286a6ede4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Transformer, a novel neural network, relies *solely* on attention mechanisms, discarding recurrence and convolutions. It achieves state-of-the-art results on machine translation tasks (English-German, English-French), offering superior quality, greater parallelization, and significantly reduced training time. The architecture also generalizes well to other tasks like parsing.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of research papers.\\\n",
        "summarize the research paper below delimited by triple backticks, \\\n",
        "in at most 50 words.\n",
        "Paper : ```{attention}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5f7e4950",
      "metadata": {
        "height": 285,
        "id": "5f7e4950",
        "outputId": "a02a3a3f-c0bf-49a4-d28b-a14863ab6053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Transformer paper solves the inefficiency of recurrent/convolutional sequence models. Its main innovation is relying *solely* on attention mechanisms, eliminating recurrence and convolutions. This matters because it achieved superior quality, better parallelization, and significantly faster training for tasks like machine translation, becoming a foundational architecture.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to summarize a technical AI research paper for software engineers \\\n",
        "who are familiar with machine learning but haven't read this specific paper.\\\n",
        "\n",
        "Summarize the research paper below delimited by triple backticks in at most 50 words, \\\n",
        "focusing on: \\\n",
        "- What problem it solves \\\n",
        "- The main innovation \\\n",
        "- Why it matters\n",
        "\n",
        "Paper : ```{attention}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "8fba051a",
      "metadata": {
        "height": 283,
        "id": "8fba051a",
        "outputId": "a21089ee-a01b-4c3b-8df2-cb82491a0b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*   **Problem/Context:** Dominant sequence transduction models rely on complex recurrent or convolutional neural networks for their encoder-decoder architectures.\n",
            "*   **Solution/Method:** The Transformer is proposed as a new, simpler network architecture based solely on attention mechanisms, entirely dispensing with recurrence and convolutions.\n",
            "*   **Impact/Results:** The Transformer achieves superior quality, is more parallelizable, requires significantly less training time, establishes new state-of-the-art results on machine translation, and generalizes well to other tasks.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize the following research paper abstract delimited by triple backticks in exactly 3 bullet points:\n",
        "\n",
        "1. Problem/Context (what gap it addresses)\n",
        "2. Solution/Method (the key innovation)\n",
        "3. Impact/Results (why it matters)\n",
        "\n",
        "Keep each bullet to one sentence maximum.\n",
        "\n",
        "Paper : ```{attention}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "637c2639",
      "metadata": {
        "height": 589,
        "id": "637c2639",
        "outputId": "acb4f395-3d50-49e3-8443-732ecfd2403c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Problem**: Traditional sequence transduction models rely on complex recurrent or convolutional neural networks, limiting parallelization and efficiency.\n",
            "**Solution**: The Transformer introduces an architecture based solely on multi-head self-attention mechanisms, completely dispensing with recurrence and convolutions.\n",
            "**Impact**: This architecture enables significant parallelization, leading to drastically reduced training times and state-of-the-art performance in various tasks.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "\n",
        "You are an expert technical writer creating paper summaries for ML engineers reviewing recent \\\n",
        "research. \\\n",
        "1. Create a 3-sentence summary for the paper below delimited by triple backticks \\\n",
        "capturing: problem ‚Üí solution ‚Üí impact \\\n",
        "2. Use precise technical terminology (e.g., \"attention mechanism\", \"parallelization\") \\\n",
        "3. Each sentence must be 15-25 words \\\n",
        "4. Focus on architectural innovations, not just performance metrics \\\n",
        "5. Write in present tense for timeless quality\n",
        "\n",
        "Let your output be in this format \\\n",
        "**Problem**: [One sentence describing what previous approaches lacked]\\\n",
        "**Solution**: [One sentence describing the key innovation] \\\n",
        "**Impact**: [One sentence describing the significance or results] \\\n",
        "\n",
        "# Example Output (for ResNet paper)\n",
        "**Problem**: Deep neural networks suffered from degradation where adding layers decreased accuracy due to optimization difficulties.\n",
        "**Solution**: Residual learning framework uses skip connections allowing gradients to flow directly through layers via identity mappings.\n",
        "**Impact**: ResNets achieved breakthrough ImageNet results and enabled training of networks exceeding 100 layers successfully.\n",
        "\n",
        "# Example Output (for BERT paper)\n",
        "**Problem**: Previous language models used unidirectional context limiting their ability to understand relationships between all words.\n",
        "**Solution**: BERT introduces bidirectional pre-training using masked language modeling and next sentence prediction simultaneously.\n",
        "**Impact**: Achieved state-of-the-art on eleven NLP tasks and revolutionized transfer learning for language understanding.\n",
        "\n",
        "\n",
        "Paper : ```{attention}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "eb28cafc",
      "metadata": {
        "height": 200,
        "id": "eb28cafc",
        "outputId": "1ddade65-6e39-4187-a6dc-605eddf94946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This paper introduces the Transformer, a new computer model for language tasks like translation. It's simpler and faster than older models because it uses a clever \"attention\" focus system instead of complex traditional methods. It achieved much better translation quality with significantly less training time.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "\n",
        "Create a summary for the research paper below delimited by triple backticks \\\n",
        "for a general audience with no technical background. \\\n",
        "Use simple language, avoid jargon, and explain in at most 50 words what the paper is about.\n",
        "Paper : ```{attention}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a0c13b6e",
      "metadata": {
        "height": 336,
        "id": "a0c13b6e",
        "outputId": "c36e7b45-94da-45dc-e69b-594309a77978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a summary for non-technical readers:\n",
            "\n",
            "1.  **The Problem**: Previous computer programs for understanding and translating language were complicated and slow to train, making it difficult to improve their performance efficiently. They struggled to process many parts of a sentence at once, which limited how quickly they could learn.\n",
            "2.  **The Solution**: The researchers developed a new, simpler computer program called the \"Transformer.\" This innovative approach focuses entirely on how different words in a sentence relate to each other, allowing it to process information much more efficiently.\n",
            "3.  **Why It Matters**: This breakthrough dramatically improved the speed and accuracy of machine translation tools and other language systems. It enables the technology powering our online translators and voice assistants to learn faster and deliver better results, making them more powerful and accessible for everyone.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "\n",
        "Create a summary for the research paper below delimited by triple backticks \\\n",
        "for non-technical readers (executives, journalists, general public) \\\n",
        "who need to understand the significance without technical details. \\\n",
        "\n",
        "Structure your summary as: \\\n",
        "1. **The Problem** (in everyday terms): What wasn't working well before? \\\n",
        "2. **The Solution** (in simple language): What did these researchers create? \\\n",
        "3. **Why It Matters** (real-world impact): How does this affect technology we use?\\\n",
        "Each section: 1-2 sentences maximum. \\\n",
        "Avoid these terms: neural networks, encoder, decoder, attention mechanism, architecture \\\n",
        "Instead use: translation tool, language system, computer program, etc.\n",
        "Paper : ```{attention}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "9bc2342f",
      "metadata": {
        "height": 421,
        "id": "9bc2342f",
        "outputId": "a763c487-5107-4245-8a03-61e041620a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previously, language-handling computer programs were complex, processing information step-by-step like a meticulous office worker. We created a streamlined system that lets computers instantly connect related words, like a conductor orchestrating an entire symphony. This innovation vastly improves digital language interpreters, making them quicker to build and more powerful for many communication tasks.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "\n",
        "Your task is to generate summary of the research paper found below \\\n",
        "for a general audience publication \\\n",
        "(like Wired, The Verge, or MIT Technology Review's explainer section). \\\n",
        "Your reader is educated but not technical. \\\n",
        "Follow these rules:\\\n",
        "1. NO technical jargon: Forbidden words include: neural network, encoder, decoder, \\\n",
        " architecture, mechanism, parameters, training, model, translation model, transformer model\n",
        " ,transformer. \\\n",
        "2. USE everyday analogies: Relate to cooking, sports, office work, travel, or other \\\n",
        " universal experiences but wisely\\\n",
        "3. Focus on impact: Readers care about \"what this enables\" not \"how it works internally\"\\\n",
        "4. 3-sentence structure: Problem (past tense) ‚Üí Innovation (what was created) ‚Üí  \\\n",
        " Impact (present/future tense) \\\n",
        "5. Each sentence: 20-30 words \\\n",
        "\n",
        "the research paper is found below delimited by triple backticks\n",
        "Paper : ```{attention}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tone Translation"
      ],
      "metadata": {
        "id": "AvN9XzF2AXez"
      },
      "id": "AvN9XzF2AXez"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "cc66b668",
      "metadata": {
        "height": 30,
        "id": "cc66b668"
      },
      "outputs": [],
      "source": [
        "wikipedia = \"\"\"\n",
        "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast \\\n",
        "to natural intelligence displayed by humans. The field studies intelligent \\\n",
        "agents‚Äîdevices that perceive their environment and take actions to achieve goals. \\\n",
        "As machines become more capable, tasks once considered intelligent are removed from \\\n",
        "AI's definition, a phenomenon called the AI effect. Modern capabilities are classified \\\n",
        "as narrow AI, designed for specific tasks rather than general intelligence. AI research \\\n",
        "began at Dartmouth College in 1956. The field has experienced cycles of excitement and \\\n",
        "disappointment, including \"AI winters\" when progress stalled and funding decreased.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to translate the following from formal to a friendly tone.\n",
        "Text: ```{wikipedia}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "qQNHlrESAjt0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "e3c01d9d-52ef-45b6-c4cf-b94c18b8bd79"
      },
      "id": "qQNHlrESAjt0",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here's that text translated into a friendlier, more conversational tone:\n",
            "\n",
            "\"So, Artificial Intelligence (AI) is basically when machines show smarts, unlike the natural intelligence we humans have. The field itself studies 'intelligent agents' ‚Äì think of them as smart gadgets that can actually sense what's going on around them and then do things to achieve their goals.\n",
            "\n",
            "Here's a fun fact: as machines get more capable, tasks we once thought were super intelligent get taken *out* of AI's definition! This quirky happening is known as the 'AI effect.' Right now, most of what we call AI is 'narrow AI.' That means it's really good at specific tasks, but it's not generally intelligent like a person.\n",
            "\n",
            "The whole idea of AI research got started way back in 1956 at Dartmouth College. It's been a bit of a rollercoaster ride ever since, with moments of huge excitement and then periods of real disappointment. They even had tough times called 'AI winters' when progress stalled and funding dried up!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following from academic language to a casual social media post for twitter\n",
        "Text: ```{wikipedia}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "GSJHq7gaAtKm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "outputId": "c0052e40-401a-4d7c-d84a-f51c3f7b65f8"
      },
      "id": "GSJHq7gaAtKm",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are a few options, choose the one that best fits your desired tone!\n",
            "\n",
            "**Option 1 (Concise & Informative):**\n",
            "\n",
            "Ever wonder what #AI really is? ü§î Basically, it's machines showing off their smarts ü§ñ ‚Äì not human intelligence. They sense their world and act to hit goals.\n",
            "\n",
            "Funny thing: once AI masters a task, we often stop calling it 'AI'! That's the #AIEffect. Today's AI is mostly 'narrow' (good at one specific thing), not generally smart (yet!). Started way back in 1956 at Dartmouth! It's had its ups & downs (even \"AI winters\"), but it's always evolving! #TechExplained\n",
            "\n",
            "---\n",
            "\n",
            "**Option 2 (A Bit More Playful):**\n",
            "\n",
            "Alright, nerds (and everyone else)! Let's demystify #AI. ü§Ø Think of it as super-smart machines doing brainy stuff, but it's *machine* brains, not human ones. They literally perceive their environment & take action to achieve goals ‚Äì pretty cool, right?\n",
            "\n",
            "Here's the kicker: once AI gets *really* good at something, we kinda go \"meh, that's not AI anymore.\" üòÇ That's the #AIEffect, folks! Most AI now is \"narrow\" (like your phone's assistant), not \"Skynet-level\" general intelligence.\n",
            "\n",
            "FYI: AI isn't new! Research started in 1956. It's had huge hype cycles and even \"AI winters\" where things froze. Wild ride! üé¢ #ArtificialIntelligence #TechTalk\n",
            "\n",
            "---\n",
            "\n",
            "**Option 3 (Very Casual):**\n",
            "\n",
            "Okay, so what *is* #AI? ü§î Simple: it's machines acting intelligent, while *we're* naturally intelligent. These techy agents basically look around, then do stuff to get what they want! üéØ\n",
            "\n",
            "And here's a weird fact: when AI gets too good at something, we take it off the \"AI\" list! ü§∑‚Äç‚ôÄÔ∏è They call it the #AIEffect. Currently, AI is mostly \"narrow\" ‚Äì like, amazing at chess, but not gonna write your novel.\n",
            "\n",
            "Fun fact: AI started way back in 1956 at Dartmouth! It's had its boom times and its \"AI winters\" (when things got quiet), proving it's been a journey! üöÄ #DidYouKnow #Tech\n",
            "\n",
            "---\n",
            "\n",
            "**Key elements used:**\n",
            "*   **Emojis:** To convey tone and break up text.\n",
            "*   **Hashtags:** For discoverability and topic grouping.\n",
            "*   **Casual language:** \"Basically,\" \"funny thing,\" \"kinda,\" \"wild ride,\" \"nerds.\"\n",
            "*   **Shorter sentences/phrases:** Easier to read quickly.\n",
            "*   **Relatable analogies/examples:** \"Skynet,\" \"phone's assistant.\"\n",
            "*   **Direct address:** \"Ever wonder,\" \"Alright, folks.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Rewrite the following text in an enthusiastic, engaging tone suitable for a tech blog targeting young professionals interested in AI.\n",
        "\n",
        "Use:\n",
        "- Conversational language\n",
        "- Use everyday lanuage\n",
        "- Active voice\n",
        "- Excitement about the topic\n",
        "- Keep it under 120 words\n",
        "\n",
        "Text: ```{wikipedia}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Hvn3OGqdAym2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5f149303-015c-4f53-fd8c-8c319e1d43fd"
      },
      "id": "Hvn3OGqdAym2",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ever wondered how machines \"think\" and make decisions? That's Artificial Intelligence (AI) ‚Äì when tech gets seriously smart! Imagine intelligent agents: devices that actually *see* their surroundings and *act* to crush specific goals. It's so wild that as AI capabilities explode, we keep redefining what counts as \"intelligent\" ‚Äì that's the awesome \"AI effect\"! Today, we're absolutely rocking \"narrow AI,\" excelling at specific tasks. While AI's journey started way back in 1956 and saw some \"winters,\" get ready because we're in an unprecedented boom of innovation right now!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "\n",
        "Your task is to Rewrite this text for a marketing landing page targeting startup founders.\n",
        "\n",
        "# Tone Requirements\n",
        "- Enthusiastic but professional\n",
        "- Use \"you\" to address the reader\n",
        "- Include 1-2 rhetorical questions\n",
        "- End with a forward-looking statement\n",
        "- Length: 80-100 words\n",
        "\n",
        "# Style Rules\n",
        "- Replace academic terms with business-friendly language\n",
        "- Use short, punchy sentences (10-15 words average)\n",
        "- Include at least one power word (revolutionary, transform, breakthrough)\n",
        "\n",
        "Text: ```{wikipedia}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "BgPhk4-QAzby",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "59edf72a-4044-498e-87f9-9f140ef6873a"
      },
      "id": "BgPhk4-QAzby",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Are you ready to unlock unprecedented potential? Artificial Intelligence isn't just a concept. It's cutting-edge machines performing intelligent tasks, dramatically augmenting human capabilities. Imagine smart systems perceiving challenges and acting to achieve *your* business goals. Forget the hype cycles of the past. Today's focused AI solutions are ready to **transform** how you operate. Are you prepared to innovate faster, smarter, and with unmatched efficiency? The future of your startup thrives on intelligent automation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "description = \"\"\"\n",
        "The CloudBook Pro is a lightweight laptop computer designed for mobile professionals and \\\n",
        "students. It features a 14-inch display with 1920x1080 resolution, providing clear  \\\n",
        "image quality for document editing and media consumption. The device weighs 1.3 kilograms \\\n",
        "and measures 18 millimeters in thickness, making it suitable for transport in standard \\\n",
        "laptop bags.The laptop is equipped with an Intel Core i5 processor, 8GB of RAM, and \\\n",
        "256GB of solid-state storage. Battery life is rated at up to 10 hours of typical use, \\\n",
        "which includes web browsing, document creation, and video streaming. The device includes \\\n",
        "two USB-C ports, one USB-A port, an HDMI output, and a headphone jack for connectivity \\\n",
        "options. The keyboard features a standard layout with 1.5mm key travel and backlit keys for \\\n",
        "low-light environments. The trackpad measures 11 centimeters by 7 centimeters and supports \\\n",
        "multi-touch gestures. The laptop runs on Windows 11 operating system and comes with a \\\n",
        "one-year manufacturer's warranty. The starting price is $799, with various configuration \\\n",
        "options available that affect the final cost.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kumYrfQGA8Mw"
      },
      "id": "kumYrfQGA8Mw",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "You are a marketing copywriter.\n",
        "Analyze the product description below and extract the key facts needed to write an engaging marketing copy.\n",
        "\n",
        "Then write a compelling, high-converting marketing copy that:\n",
        "- emphasizes the product name and core features\n",
        "- clearly communicates benefits to the target audience\n",
        "- speaks in a persuasive, energetic, value-focused tone\n",
        "- is suitable for tech-savvy professionals and students\n",
        "- avoids unnecessary technical jargon\n",
        "- stays concise (120 words max)\n",
        "\n",
        "Output ONLY the final marketing copy. Do NOT include explanations.\n",
        "Output the final marketing copy in 3 English, Yoruba and Igbo\n",
        "Text: ```{description}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "luJA8WMJBBng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "731a45e2-1a18-4e43-c25e-1029a97028a2"
      },
      "id": "luJA8WMJBBng",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**English**\n",
            "Unleash your productivity with the **CloudBook Pro**! Designed for dynamic professionals and students, this ultra-light (1.3kg), thin laptop features a stunning 14-inch FHD display for crisp visuals. Power through tasks with its Intel Core i5 processor, 8GB RAM, and lightning-fast 256GB SSD. Enjoy up to 10 hours of battery life and stay connected with versatile USB-C, USB-A, and HDMI ports. Type comfortably anywhere thanks to the backlit keyboard. Running on Windows 11, the CloudBook Pro is your ultimate mobile companion. Elevate your efficiency today!\n",
            "\n",
            "**Yoruba**\n",
            "·π¢i·π£·∫π p·∫πlu agbara p·∫πlu **CloudBook Pro**! Ti a ·π£e fun aw·ªçn akosemose ti n l·ªç ati aw·ªçn ·ªçm·ªç ile-iwe, k·ªçmputa alagbeka f·∫πl·∫πf·∫πl·∫π yii (1.3kg) ni ifihan 14-inch FHD ti o l·∫πwa fun aworan to m·ªç. ·π¢i·π£·∫π k·ªçja aw·ªçn i·π£·∫π-·π£i·π£e p·∫πlu Intel Core i5, 8GB RAM, ati 256GB SSD ti o yara. Gbadun to wakati m·∫πwa batiri ati duro ni asop·ªç p·∫πlu aw·ªçn ebute USB-C, USB-A, HDMI. T·∫π ni ir·ªçrun nibikibi p·∫πlu keyboard ti o ni ina. P·∫πlu Windows 11, CloudBook Pro ni ·∫πl·∫πgb·∫π alagbeka r·∫π ti o ga jul·ªç. Mu il·ªçsiwaju r·∫π p·ªç si loni!\n",
            "\n",
            "**Igbo**\n",
            "T·ª•te ikike ar·ª•m·ªçr·ª• g·ªã na **CloudBook Pro**! Emere maka nd·ªã ·ªçkachamara na ·ª•m·ª• akw·ª•kw·ªç na-akwaghar·ªã akwaghar·ªã, lapt·ªç·ªçp·ª• a d·ªã ·ªçk·ª• (1.3kg), d·ªãkwa mkpa, nwere ngosip·ª•ta 14-inch FHD mara mma maka onyonyo doro anya. Jiri Intel Core i5 processor ya, 8GB RAM, na 256GB SSD d·ªã ngwa ngwa r·ª•·ªç ·ªçr·ª•. Nweta ike batr·ªã ruo awa iri ma jik·ªç·ªç site na ·ªçd·ª• USB-C, USB-A, na HDMI d·ªã iche iche. Dehie ngwa ngwa ebe ·ªç b·ª•la n'ihi ah·ª•igodo nwere ·ªçk·ª• az·ª•. Na-eji Windows 11 ar·ª• ·ªçr·ª•, CloudBook Pro b·ª• enyi g·ªã kachas·ªã mma na-akwaghar·ªã akwaghar·ªã. Bulie ar·ª•m·ªçr·ª• g·ªã taa!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uLbdWQabAj0C"
      },
      "id": "uLbdWQabAj0C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w5ko6yeHAj33"
      },
      "id": "w5ko6yeHAj33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5efb5548",
      "metadata": {
        "height": 30,
        "id": "5efb5548"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d05d8a20-86f2-4613-835e-41c49a504b5b",
      "metadata": {
        "height": 30,
        "id": "d05d8a20-86f2-4613-835e-41c49a504b5b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}